{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  rating  \\\n",
       "0  Home_and_Kitchen     5.0   \n",
       "1  Home_and_Kitchen     5.0   \n",
       "2  Home_and_Kitchen     5.0   \n",
       "3  Home_and_Kitchen     1.0   \n",
       "4  Home_and_Kitchen     5.0   \n",
       "\n",
       "                                                text  label  \n",
       "0  Love this!  Well made, sturdy, and very comfor...      1  \n",
       "1  love it, a great upgrade from the original.  I...      1  \n",
       "2  This pillow saved my back. I love the look and...      1  \n",
       "3  Missing information on how to use it, but it i...      1  \n",
       "4  Very nice set. Good quality. We have had the s...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fake_reviews_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data(df):\n",
    "    # Load stop words and initialize stemmer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Preprocessing function: remove stop words and apply stemming\n",
    "    def preprocess_text(text):\n",
    "        words = text.split()\n",
    "        filtered_words = [stemmer.stem(word) for word in words if word.lower() not in stop_words]\n",
    "        return ' '.join(filtered_words)\n",
    "\n",
    "    # Split the data into training and testing sets (80% train, 20% test)\n",
    "    X = df['text']  # Features (text data)\n",
    "    y = df['label']  # Labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply preprocessing to the training and testing sets separately\n",
    "    X_train = X_train.apply(preprocess_text)\n",
    "    X_test = X_test.apply(preprocess_text)\n",
    "\n",
    "    # Tokenize and pad sequences\n",
    "    max_words = 10000  # Hardcoded maximum number of words\n",
    "    max_len = 100      # Hardcoded maximum sequence length\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "    X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "    # Return the processed datasets and tokenizer\n",
    "    return X_train_pad, X_test_pad, y_train, y_test, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (32420, 100) (32420,)\n",
      "Test shape: (8106, 100) (8106,)\n"
     ]
    }
   ],
   "source": [
    "# Example usage for preprocessing\n",
    "X_train, X_test, y_train, y_test, tokenizer = preprocess_and_split_data(df)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.5256 - loss: 0.6878 - val_accuracy: 0.7472 - val_loss: 0.5305\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.8233 - loss: 0.3987 - val_accuracy: 0.8823 - val_loss: 0.2776\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9203 - loss: 0.1972 - val_accuracy: 0.8894 - val_loss: 0.2682\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9457 - loss: 0.1361 - val_accuracy: 0.8917 - val_loss: 0.2865\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9621 - loss: 0.1018 - val_accuracy: 0.8880 - val_loss: 0.3150\n",
      "Epoch 6/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9633 - loss: 0.0972 - val_accuracy: 0.8885 - val_loss: 0.3219\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.2663\n",
      "GRU Test Accuracy: 0.893905758857727\n"
     ]
    }
   ],
   "source": [
    "# Define GRU-based model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=32, input_length=100),  # Match tokenizer and padding\n",
    "    GRU(32),\n",
    "    Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the GRU model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU with Dropout Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.5165 - loss: 0.6917 - val_accuracy: 0.5242 - val_loss: 0.6829\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.5838 - loss: 0.6389 - val_accuracy: 0.8543 - val_loss: 0.3273\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.8849 - loss: 0.2854 - val_accuracy: 0.8826 - val_loss: 0.2749\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.9213 - loss: 0.2021 - val_accuracy: 0.8896 - val_loss: 0.2671\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.9393 - loss: 0.1622 - val_accuracy: 0.8886 - val_loss: 0.2828\n",
      "Epoch 6/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - accuracy: 0.9510 - loss: 0.1341 - val_accuracy: 0.8883 - val_loss: 0.2995\n",
      "Epoch 7/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9614 - loss: 0.1100 - val_accuracy: 0.8890 - val_loss: 0.3104\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2683\n",
      "GRU Test Accuracy: 0.8892178535461426\n"
     ]
    }
   ],
   "source": [
    "# Define GRU-based model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=32, input_length=100),  # Match tokenizer and padding\n",
    "    GRU(32, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the GRU model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Embedding Dim and GRU from 32 to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 41ms/step - accuracy: 0.5133 - loss: 0.6908 - val_accuracy: 0.7838 - val_loss: 0.4853\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.8379 - loss: 0.3779 - val_accuracy: 0.8812 - val_loss: 0.2763\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 39ms/step - accuracy: 0.9204 - loss: 0.2048 - val_accuracy: 0.8868 - val_loss: 0.2685\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 38ms/step - accuracy: 0.9453 - loss: 0.1506 - val_accuracy: 0.8885 - val_loss: 0.2746\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 38ms/step - accuracy: 0.9579 - loss: 0.1147 - val_accuracy: 0.8882 - val_loss: 0.3108\n",
      "Epoch 6/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.9666 - loss: 0.0933 - val_accuracy: 0.8927 - val_loss: 0.3120\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.2677\n",
      "GRU Test Accuracy: 0.8953861594200134\n"
     ]
    }
   ],
   "source": [
    "# Define GRU-based model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),  # Match tokenizer and padding\n",
    "    GRU(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the GRU model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 47ms/step - accuracy: 0.7476 - loss: 0.4677 - val_accuracy: 0.8865 - val_loss: 0.2683\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9293 - loss: 0.1768 - val_accuracy: 0.9067 - val_loss: 0.2208\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - accuracy: 0.9575 - loss: 0.1157 - val_accuracy: 0.9047 - val_loss: 0.2372\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9710 - loss: 0.0803 - val_accuracy: 0.9024 - val_loss: 0.2579\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9795 - loss: 0.0603 - val_accuracy: 0.8988 - val_loss: 0.3199\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9002 - loss: 0.2397\n",
      "Bidirectional GRU Test Accuracy: 0.9031581282615662\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64)),  # Wrap GRU in Bidirectional and increase units slightly\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding additional dense layer to Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 45ms/step - accuracy: 0.7386 - loss: 0.4637 - val_accuracy: 0.9013 - val_loss: 0.2403\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9352 - loss: 0.1628 - val_accuracy: 0.9126 - val_loss: 0.2113\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 46ms/step - accuracy: 0.9648 - loss: 0.0958 - val_accuracy: 0.9092 - val_loss: 0.2475\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 46ms/step - accuracy: 0.9764 - loss: 0.0638 - val_accuracy: 0.8998 - val_loss: 0.3154\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9821 - loss: 0.0498 - val_accuracy: 0.8994 - val_loss: 0.3291\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9100 - loss: 0.2309\n",
      "Bidirectional GRU Test Accuracy: 0.9100666046142578\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64)),\n",
    "    Dense(32, activation='relu'),  # New hidden layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Dropout to the Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.5022 - val_accuracy: 0.8927 - val_loss: 0.2509\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9263 - loss: 0.1800 - val_accuracy: 0.9028 - val_loss: 0.2334\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9553 - loss: 0.1165 - val_accuracy: 0.9041 - val_loss: 0.2388\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - accuracy: 0.9723 - loss: 0.0759 - val_accuracy: 0.9064 - val_loss: 0.2951\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 47ms/step - accuracy: 0.9813 - loss: 0.0539 - val_accuracy: 0.8981 - val_loss: 0.3182\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8961 - loss: 0.2460\n",
      "Bidirectional GRU Test Accuracy: 0.8994572162628174\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64, return_sequences=False)),\n",
    "    Dropout(0.2),  # Regularizes GRU output\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding dropout seems to make it worse (I tried both 0.2 and 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average review length in tokens: 32.007920840941615\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'text' column from the DataFrame\n",
    "texts = df['text']\n",
    "\n",
    "# Initialize the tokenizer and fit it on the texts\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Convert the texts to sequences of tokens\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Calculate the lengths of each review in tokens\n",
    "review_lengths = [len(seq) for seq in sequences]\n",
    "\n",
    "# Calculate the average review length\n",
    "average_length = sum(review_lengths) / len(review_lengths)\n",
    "print(\"Average review length in tokens:\", average_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 44ms/step - accuracy: 0.7012 - loss: 0.5093 - val_accuracy: 0.8846 - val_loss: 0.2628\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 45ms/step - accuracy: 0.9203 - loss: 0.1899 - val_accuracy: 0.9027 - val_loss: 0.2330\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9481 - loss: 0.1284 - val_accuracy: 0.9041 - val_loss: 0.2473\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 45ms/step - accuracy: 0.9683 - loss: 0.0880 - val_accuracy: 0.9053 - val_loss: 0.2796\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9733 - loss: 0.0710 - val_accuracy: 0.9021 - val_loss: 0.3343\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8986 - loss: 0.2417\n",
      "Bidirectional GRU Test Accuracy: 0.8984702825546265\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64, return_sequences=False)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Increasing Embedding Dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 56ms/step - accuracy: 0.7316 - loss: 0.4872 - val_accuracy: 0.8967 - val_loss: 0.2481\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 57ms/step - accuracy: 0.9323 - loss: 0.1734 - val_accuracy: 0.9098 - val_loss: 0.2182\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 55ms/step - accuracy: 0.9631 - loss: 0.0953 - val_accuracy: 0.8988 - val_loss: 0.2650\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 57ms/step - accuracy: 0.9768 - loss: 0.0648 - val_accuracy: 0.9052 - val_loss: 0.2811\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 56ms/step - accuracy: 0.9848 - loss: 0.0435 - val_accuracy: 0.9056 - val_loss: 0.3381\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9054 - loss: 0.2344\n",
      "Bidirectional GRU Test Accuracy: 0.9031581282615662\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "    Bidirectional(GRU(64)),\n",
    "    Dense(32, activation='relu'),  # New hidden layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Additonal GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 96ms/step - accuracy: 0.7558 - loss: 0.4478 - val_accuracy: 0.9052 - val_loss: 0.2379\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 102ms/step - accuracy: 0.9349 - loss: 0.1661 - val_accuracy: 0.9098 - val_loss: 0.2248\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 103ms/step - accuracy: 0.9621 - loss: 0.1038 - val_accuracy: 0.9007 - val_loss: 0.2701\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 99ms/step - accuracy: 0.9687 - loss: 0.0860 - val_accuracy: 0.9056 - val_loss: 0.2888\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 98ms/step - accuracy: 0.9806 - loss: 0.0576 - val_accuracy: 0.9005 - val_loss: 0.2995\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9017 - loss: 0.2378\n",
      "Bidirectional GRU Test Accuracy: 0.9018011093139648\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64, return_sequences=True)),\n",
    "    Bidirectional(GRU(64)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Barth Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - accuracy: 0.7558 - loss: 0.4565 - val_accuracy: 0.5193 - val_loss: 3.3787\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.9225 - loss: 0.1931 - val_accuracy: 0.7933 - val_loss: 0.5860\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 44ms/step - accuracy: 0.9554 - loss: 0.1220 - val_accuracy: 0.8711 - val_loss: 0.3431\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 44ms/step - accuracy: 0.9667 - loss: 0.0861 - val_accuracy: 0.8834 - val_loss: 0.3123\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 44ms/step - accuracy: 0.9781 - loss: 0.0599 - val_accuracy: 0.8933 - val_loss: 0.3302\n",
      "Epoch 6/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 46ms/step - accuracy: 0.9833 - loss: 0.0451 - val_accuracy: 0.8974 - val_loss: 0.3486\n",
      "Epoch 7/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 46ms/step - accuracy: 0.9866 - loss: 0.0383 - val_accuracy: 0.8837 - val_loss: 0.5110\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8826 - loss: 0.3192\n",
      "Bidirectional GRU Test Accuracy: 0.8871206641197205\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64)),\n",
    "    BatchNormalization(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with addiitonal GRU layer with driopout and also another dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 122ms/step - accuracy: 0.7382 - loss: 0.4794 - val_accuracy: 0.8940 - val_loss: 0.2447\n",
      "Epoch 2/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 146ms/step - accuracy: 0.9247 - loss: 0.1831 - val_accuracy: 0.9064 - val_loss: 0.2346\n",
      "Epoch 3/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 205ms/step - accuracy: 0.9546 - loss: 0.1150 - val_accuracy: 0.9011 - val_loss: 0.2585\n",
      "Epoch 4/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 209ms/step - accuracy: 0.9693 - loss: 0.0802 - val_accuracy: 0.9105 - val_loss: 0.2518\n",
      "Epoch 5/20\n",
      "\u001b[1m811/811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 206ms/step - accuracy: 0.9783 - loss: 0.0603 - val_accuracy: 0.8976 - val_loss: 0.2745\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.9044 - loss: 0.2498\n",
      "Bidirectional GRU Test Accuracy: 0.9059955477714539\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.1)),  # Added GRU layer with dropout\n",
    "    Bidirectional(GRU(64)),  # Original GRU layer\n",
    "    Dense(64, activation='relu'),  # Added Dense layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(32, activation='relu'),  # Original Dense layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with a bigger val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 74ms/step - accuracy: 0.7135 - loss: 0.4913 - val_accuracy: 0.8949 - val_loss: 0.2484\n",
      "Epoch 2/20\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 80ms/step - accuracy: 0.9240 - loss: 0.1860 - val_accuracy: 0.9050 - val_loss: 0.2290\n",
      "Epoch 3/20\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 80ms/step - accuracy: 0.9583 - loss: 0.1061 - val_accuracy: 0.8999 - val_loss: 0.2612\n",
      "Epoch 4/20\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 79ms/step - accuracy: 0.9762 - loss: 0.0661 - val_accuracy: 0.9013 - val_loss: 0.2998\n",
      "Epoch 5/20\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 80ms/step - accuracy: 0.9812 - loss: 0.0521 - val_accuracy: 0.8940 - val_loss: 0.3205\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8999 - loss: 0.2445\n",
      "Bidirectional GRU Test Accuracy: 0.900937557220459\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64)),\n",
    "    Dense(32, activation='relu'),  # New hidden layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.35,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying diff batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 95ms/step - accuracy: 0.6821 - loss: 0.5441 - val_accuracy: 0.8933 - val_loss: 0.2489\n",
      "Epoch 2/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 109ms/step - accuracy: 0.9256 - loss: 0.1831 - val_accuracy: 0.9084 - val_loss: 0.2235\n",
      "Epoch 3/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 108ms/step - accuracy: 0.9600 - loss: 0.1032 - val_accuracy: 0.9085 - val_loss: 0.2435\n",
      "Epoch 4/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 110ms/step - accuracy: 0.9759 - loss: 0.0683 - val_accuracy: 0.9045 - val_loss: 0.2981\n",
      "Epoch 5/20\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 110ms/step - accuracy: 0.9838 - loss: 0.0472 - val_accuracy: 0.8976 - val_loss: 0.3157\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9006 - loss: 0.2407\n",
      "Bidirectional GRU Test Accuracy: 0.9029114246368408\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64)),\n",
    "    Dense(32, activation='relu'),  # New hidden layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 45ms/step - accuracy: 0.6918 - loss: 0.5235 - val_accuracy: 0.8849 - val_loss: 0.2623\n",
      "Epoch 2/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 45ms/step - accuracy: 0.9061 - loss: 0.2280 - val_accuracy: 0.8987 - val_loss: 0.2467\n",
      "Epoch 3/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 45ms/step - accuracy: 0.9248 - loss: 0.1829 - val_accuracy: 0.9072 - val_loss: 0.2192\n",
      "Epoch 4/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 45ms/step - accuracy: 0.9405 - loss: 0.1491 - val_accuracy: 0.9139 - val_loss: 0.2108\n",
      "Epoch 5/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6559s\u001b[0m 4s/step - accuracy: 0.9511 - loss: 0.1239 - val_accuracy: 0.9144 - val_loss: 0.2184\n",
      "Epoch 6/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11281s\u001b[0m 7s/step - accuracy: 0.9601 - loss: 0.1058 - val_accuracy: 0.9155 - val_loss: 0.2364\n",
      "Epoch 7/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20772s\u001b[0m 13s/step - accuracy: 0.9674 - loss: 0.0895 - val_accuracy: 0.9116 - val_loss: 0.2707\n",
      "Epoch 8/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9161s\u001b[0m 6s/step - accuracy: 0.9718 - loss: 0.0756 - val_accuracy: 0.9062 - val_loss: 0.2509\n",
      "Epoch 9/20\n",
      "\u001b[1m1621/1621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 46ms/step - accuracy: 0.9757 - loss: 0.0683 - val_accuracy: 0.9065 - val_loss: 0.2797\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9113 - loss: 0.2485\n",
      "Bidirectional GRU Test Accuracy: 0.9125339388847351\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=100),\n",
    "    Bidirectional(GRU(64)),\n",
    "    Dense(32, activation='relu'),  # New hidden layer\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_split=0.20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Bidirectional GRU Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
